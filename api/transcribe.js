import { IncomingForm } from 'formidable';
import fs from 'fs';
import SpeechToTextV1 from 'ibm-watson/speech-to-text/v1.js';
import { IamAuthenticator } from 'ibm-watson/auth/index.js';

export const config = {
  api: {
    bodyParser: false,
  },
};

export default async function handler(req, res) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  // 1. L·∫•y API Key t·ª´ bi·∫øn m√¥i tr∆∞·ªùng Vercel
  const IBM_API_KEY = process.env.SPEECH_TO_TEXT_APIKEY || process.env.IBM_API_KEY;
  const IBM_URL = process.env.SPEECH_TO_TEXT_URL || process.env.IBM_URL;
  
  if (!IBM_API_KEY || !IBM_URL) {
    console.error('‚ùå THI·∫æU IBM CREDENTIALS!');
    return res.status(500).json({ 
      error: 'IBM credentials not configured. Please set SPEECH_TO_TEXT_APIKEY and SPEECH_TO_TEXT_URL in Vercel.' 
    });
  }

  try {
    // 2. Nh·∫≠n file audio t·ª´ client
    const data = await new Promise((resolve, reject) => {
      const form = new IncomingForm();
      form.parse(req, (err, fields, files) => {
        if (err) return reject(err);
        resolve({ fields, files });
      });
    });

    const file = data.files.audio;
    if (!file) {
      return res.status(400).json({ error: 'No audio file uploaded' });
    }

    // L·∫•y ƒë∆∞·ªùng d·∫´n file t·∫°m
    const filePath = Array.isArray(file) ? file[0].filepath : file.filepath;
    
    // --- KH·ªûI T·∫†O IBM WATSON ---
    const speechToText = new SpeechToTextV1({
      authenticator: new IamAuthenticator({
        apikey: IBM_API_KEY,
      }),
      serviceUrl: IBM_URL,
    });

    // 3. X√ÅC ƒê·ªäNH CONTENT-TYPE (QUAN TR·ªåNG: S·ª¨A L·ªñI T·∫†I ƒê√ÇY)
    // Thay v√¨ d√πng 'audio/webm;codecs=opus' g√¢y l·ªói, ta ch·ªâ d√πng 'audio/webm'
    // IBM s·∫Ω t·ª± ƒë·ªông detect codec b√™n trong.
    const mimeType = (Array.isArray(file) ? file[0].mimetype : file.mimetype) || 'audio/webm';
    
    let contentType = 'audio/webm'; // M·∫∑c ƒë·ªãnh an to√†n nh·∫•t cho Web
    
    if (mimeType.includes('wav')) {
      contentType = 'audio/wav';
    } else if (mimeType.includes('ogg')) {
      contentType = 'audio/ogg';
    } else if (mimeType.includes('mp3')) {
      contentType = 'audio/mp3';
    }
    // L∆∞u √Ω: ƒê√£ x√≥a ƒëo·∫°n check "codecs=opus" ƒë·ªÉ tr√°nh l·ªói transcode

    const params = {
      audio: fs.createReadStream(filePath),
      contentType: contentType,
      model: 'fr-FR_BroadbandModel', // Model ti·∫øng Ph√°p chu·∫©n
      
      // C√°c settings gi√∫p nh·∫≠n di·ªán t·ªët h∆°n
      backgroundAudioSuppression: 0.5, // L·ªçc ·ªìn
      speechDetectorSensitivity: 0.5,
      smartFormatting: true,
    };

    console.log(`üì§ Sending to IBM: ${contentType} (Model: ${params.model})`);

    // 4. G·ª≠i l√™n IBM
    const { result } = await speechToText.recognize(params);
    
    // 5. L·∫•y k·∫øt qu·∫£ text
    const transcripts = result.results
      .map(r => r.alternatives[0].transcript)
      .join(' ')
      .trim();

    console.log('‚úÖ IBM Result:', transcripts);

    return res.status(200).json({ text: transcripts || '' });

  } catch (error) {
    console.error('‚ùå IBM ERROR:', error.message);
    
    // Log chi ti·∫øt n·∫øu c√≥
    if (error.body) {
      console.error('IBM Error Body:', error.body);
    }

    return res.status(500).json({ 
      error: error.message || 'Error processing audio',
      details: error.body || null
    });
  }
}
