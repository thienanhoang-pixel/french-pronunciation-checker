import { IncomingForm } from 'formidable';
import fs from 'fs';
import SpeechToTextV1 from 'ibm-watson/speech-to-text/v1.js';
import { IamAuthenticator } from 'ibm-watson/auth/index.js';

export const config = {
  api: {
    bodyParser: false,
  },
};

export default async function handler(req, res) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  // ‚úÖ KI·ªÇM TRA API KEY - H·ªó tr·ª£ c·∫£ 2 format
  const IBM_API_KEY = process.env.SPEECH_TO_TEXT_APIKEY || process.env.IBM_API_KEY;
  const IBM_URL = process.env.SPEECH_TO_TEXT_URL || process.env.IBM_URL;
  
  if (!IBM_API_KEY || !IBM_URL) {
    console.error('‚ùå THI·∫æU IBM CREDENTIALS!');
    console.error('SPEECH_TO_TEXT_APIKEY:', process.env.SPEECH_TO_TEXT_APIKEY ? 'C√≥' : 'THI·∫æU');
    console.error('SPEECH_TO_TEXT_URL:', process.env.SPEECH_TO_TEXT_URL ? 'C√≥' : 'THI·∫æU');
    return res.status(500).json({ 
      error: 'IBM credentials not configured. Please set SPEECH_TO_TEXT_APIKEY and SPEECH_TO_TEXT_URL in Vercel.' 
    });
  }

  console.log('‚úÖ IBM Credentials found');
  console.log('üîó IBM URL:', IBM_URL);

  try {
    // Nh·∫≠n file audio
    const data = await new Promise((resolve, reject) => {
      const form = new IncomingForm();
      form.parse(req, (err, fields, files) => {
        if (err) return reject(err);
        resolve({ fields, files });
      });
    });

    const audioFile = data.files.audio;
    if (!audioFile) {
      return res.status(400).json({ error: 'Kh√¥ng t√¨m th·∫•y file audio' });
    }

    const filePath = Array.isArray(audioFile) ? audioFile[0].filepath : audioFile.filepath;
    console.log('üìÅ File path:', filePath);

    // Kh·ªüi t·∫°o IBM Watson
    const speechToText = new SpeechToTextV1({
      authenticator: new IamAuthenticator({
        apikey: IBM_API_KEY,
      }),
      serviceUrl: IBM_URL,
    });

    console.log('üé§ ƒêang g·ª≠i audio ƒë·∫øn IBM...');

    // ‚úÖ Th·ª≠ v·ªõi c√°c config kh√°c nhau
    const params = {
      audio: fs.createReadStream(filePath),
      contentType: 'audio/webm;codecs=opus', // Ch√≠nh x√°c h∆°n cho WebM
      model: 'fr-FR_BroadbandModel',
      
      // L·ªçc nhi·ªÖu
      backgroundAudioSuppression: 0.5,
      speechDetectorSensitivity: 0.4,
      
      // C·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c
      smartFormatting: true,
      profanityFilter: false,
      maxAlternatives: 1,
    };

    console.log('üì§ Params:', {
      contentType: params.contentType,
      model: params.model,
    });

    const { result } = await speechToText.recognize(params);
    
    console.log('üì• IBM response:', JSON.stringify(result, null, 2));

    // L·∫•y transcript
    const transcripts = result.results
      .map(r => r.alternatives[0].transcript)
      .join(' ')
      .trim();

    console.log('‚úÖ Transcript:', transcripts);
    console.log('üìä S·ªë chunks:', result.results.length);

    if (!transcripts || transcripts.length === 0) {
      console.log('‚ö†Ô∏è IBM kh√¥ng nghe ƒë∆∞·ª£c g√¨');
      return res.status(200).json({ text: '' });
    }

    return res.status(200).json({ text: transcripts });

  } catch (error) {
    // ‚úÖ Log chi ti·∫øt l·ªói
    console.error('‚ùå IBM ERROR:', error);
    console.error('Error name:', error.name);
    console.error('Error message:', error.message);
    console.error('Error code:', error.code);
    console.error('Error stack:', error.stack);
    
    // N·∫øu c√≥ response t·ª´ IBM
    if (error.body) {
      console.error('IBM Response Body:', JSON.stringify(error.body, null, 2));
    }
    if (error.statusText) {
      console.error('IBM Status Text:', error.statusText);
    }
    if (error.status) {
      console.error('IBM Status Code:', error.status);
    }

    return res.status(500).json({ 
      error: error.message || 'IBM Watson error',
      details: error.body || error.statusText || 'No details available',
      code: error.code || error.status || 'UNKNOWN'
    });
  }
}
